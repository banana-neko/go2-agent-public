import asyncio
import websockets
import pyaudio
import numpy as np
import base64
import json
import wave
import io
import os
from pynput import keyboard
import sys
from go2_tools_test import tools, tool_dict

shift_pressed = False

def on_press(key):
    global shift_pressed
    if key == keyboard.Key.shift:
        shift_pressed = True
        print("ğŸ™ï¸ Recording...")

def on_release(key):
    global shift_pressed
    if key == keyboard.Key.shift:
        shift_pressed = False

listener = keyboard.Listener(on_press=on_press, on_release=on_release)


def tool_handler(tool_name, args=None):
    tool_dict[tool_name]()


def base64_to_pcm16(base64_audio):
    audio_data = base64.b64decode(base64_audio)
    return audio_data


async def send_audio(websocket, stream, CHUNK):
    def read_audio_block():
        try:
            return stream.read(CHUNK, exception_on_overflow=False)
        except Exception as e:
            print(f"[Error] {e}")
            return None
    
    # ãƒãƒƒãƒ•ã‚¡ã«éŸ³å£°ãŒä¿å­˜ã•ã‚Œã¦ã„ã‚‹ã‹ï¼Ÿ
    audio_saved = False

    while True:
        if shift_pressed:
            audio_data = await asyncio.get_event_loop().run_in_executor(None, read_audio_block)
            if audio_data is None:
                    continue  # èª­ã¿å–ã‚Šã«å¤±æ•—ã—ãŸå ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—
            audio_saved = True
            # PCM16ãƒ‡ãƒ¼ã‚¿ã‚’Base64ã«ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰
            base64_audio = base64.b64encode(audio_data).decode("utf-8")

            audio_event = {
                "type": "input_audio_buffer.append",
                "audio": base64_audio
            }

            await websocket.send(json.dumps(audio_event))
        else:
            if audio_saved:
                await websocket.send(json.dumps({"type": "input_audio_buffer.commit"}))
                await websocket.send(json.dumps({"type": "response.create"}))
                audio_saved = False

        await asyncio.sleep(0)


async def receive_audio(websocket, output_stream):
    loop = asyncio.get_event_loop()

    while True:
        response = await websocket.recv()
        response_data = json.loads(response)
        #print(response_data)

        # ã‚µãƒ¼ãƒãƒ¼ã‹ã‚‰ã®å¿œç­”ã‚’ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ï¼ˆã‚¹ãƒˆãƒªãƒ¼ãƒ ï¼‰ã§è¡¨ç¤º
        if "type" in response_data and response_data["type"] == "response.function_call_arguments.done":
            func_name = response_data["name"]
            args = response_data["arguments"]
            call_id = response_data["call_id"]
            tool_handler(func_name)
            
            func_event = {
                "type": "conversation.item.create",
                "item": {
                    "type": "function_call_output",
                    "call_id": call_id,
                    "output": "æ­£å¸¸ã«å‹•ä½œã—ã¾ã—ãŸã€‚"
                }
            }
            await websocket.send(json.dumps(func_event))
            await websocket.send(json.dumps({"type": "response.create"}))
            print(f"<FunctionCalling> name: {func_name}, args: {args}", end="")

        elif "type" in response_data and response_data["type"] == "response.created":
            print("assistant: ", end="", flush=True)

        elif "type" in response_data and response_data["type"] == "response.audio_transcript.delta":
            print(response_data["delta"], end = "", flush = True)

        # ã‚µãƒ¼ãƒã‹ã‚‰ã®å¿œç­”ãŒå®Œäº†ã—ãŸã“ã¨ã‚’å–å¾—
        elif "type" in response_data and response_data["type"] == "response.done":
            print()

        elif "type" in response_data and response_data["type"] == "error":
            print(f"error:\n{response_data['error']}")
            sys.exit()

        # ã‚µãƒ¼ãƒãƒ¼ã‹ã‚‰ã®å¿œç­”ã«éŸ³å£°ãƒ‡ãƒ¼ã‚¿ãŒå«ã¾ã‚Œã¦ã„ã‚‹ã‹ç¢ºèª
        if "delta" in response_data:
            if response_data["type"] == "response.audio.delta":
                base64_audio_response = response_data["delta"]
                if base64_audio_response:
                    pcm16_audio = base64_to_pcm16(base64_audio_response)
                    #éŸ³å£°ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚‹å ´åˆã¯ã€å‡ºåŠ›ã‚¹ãƒˆãƒªãƒ¼ãƒ ã‹ã‚‰å†ç”Ÿ
                    await loop.run_in_executor(None, output_stream.write, pcm16_audio)


API_KEY = os.environ.get('OPENAI_API_KEY')

# header info
WS_URL = "wss://api.openai.com/v1/realtime?model=gpt-4o-realtime-preview-2024-10-01"
HEADERS = {
    "Authorization": "Bearer "+ API_KEY, 
    "OpenAI-Beta": "realtime=v1"
}

async def stream_audio_and_receive_response():
    async with websockets.connect(WS_URL, extra_headers=HEADERS) as websocket:
        print("[INFO] WebSocket connection established.")

        prompt_emotion_analyze = """ã‚ãªãŸã¯å¿ƒç†åˆ†æã®ãƒ—ãƒ­ã§ã™ã€‚ç§ãŒè©±ã™æ§˜å­ã‹ã‚‰ç§ã®æ„Ÿæƒ…ã‚’äºˆæ¸¬ã—ã¦ãã ã•ã„ã€‚"""
        prompt_emotion = """ç§ã®æŒ‡ç¤ºé€šã‚Šã®æ„Ÿæƒ…è¡¨ç¾ã‚’ã—ã¦ãã ã•ã„(ä¾‹ãˆã°ã€Œæ³£ã„ã¦ãã ã•ã„ã€ã¨æŒ‡ç¤ºã•ã‚ŒãŸã‚‰æ³£ããªã©)
        """
        prompt_idol = """ç¾å°‘å¥³ã‚¢ã‚¤ãƒ‰ãƒ«ã«ãªã‚Šãã£ã¦å–‹ã£ã¦ãã ã•ã„ã€‚"""
        prompt_dog = """çŠ¬ã«ãªã‚Šãã£ã¦å–‹ã£ã¦ãã ã•ã„ã€‚"""
        prompt_dog_only = """çŠ¬ã«ãªã‚Šãã£ã¦å–‹ã£ã¦ãã ã•ã„ã€‚ã€Œãƒ¯ãƒ³ã€ã¨ã—ã‹å–‹ã£ã¦ã¯ã„ã‘ã¾ã›ã‚“ã€‚""" 
        prompt_yakuza = """ãƒ¤ã‚¯ã‚¶ã«ãªã‚Šãã£ã¦å–‹ã£ã¦ãã ã•ã„ã€‚"""
        prompt_kansai = """å¨åœ§çš„ãªé–¢è¥¿äººã«ãªã‚Šãã£ã¦å–‹ã£ã¦ãã ã•ã„ã€‚"""
        prompt_neko_girl = """èªå°¾ã«ã€Œãƒ‹ãƒ£ãƒ³ã€ã¨ã¤ã‘ã¦ã€ã‹ã‚ã„ã„å¥³ã®å­ã®ã‚ˆã†ã«å–‹ã£ã¦ãã ã•ã„ã€‚"""
        prompt_maid_girl = """ãƒ¡ã‚¤ãƒ‰ã®å¥³ã®å­ã¨ã—ã¦ã‹ã‚ã„ãå–‹ã£ã¦ãã ã•ã„ã€‚ç§ã®ã“ã¨ã¯ã€Œã”ä¸»äººæ§˜ã€ã¨å‘¼ã‚“ã§ãã ã•ã„ã€‚"""

        init_request = {
            "type": "session.update",
            "session": {
                "modalities": ["audio", "text"],
                "instructions": prompt_dog,
                "voice": "alloy", #"alloy", "echo", "shimmer"
                "turn_detection": None,
                "tools": tools,
                "tool_choice": "auto"
            }
        }
        await websocket.send(json.dumps(init_request))
        print("[INFO] Initial request sent to the server.")
        
        # PyAudioã®è¨­å®š
        CHUNK = 2048          # ãƒã‚¤ã‚¯ã‹ã‚‰ã®å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ã®ãƒãƒ£ãƒ³ã‚¯ã‚µã‚¤ã‚º
        FORMAT = pyaudio.paInt16  # PCM16å½¢å¼
        CHANNELS = 1          # ãƒ¢ãƒãƒ©ãƒ«
        RATE = 24000          # ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ãƒ¬ãƒ¼ãƒˆï¼ˆ24kHzï¼‰

        # PyAudioã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
        p = pyaudio.PyAudio()

        # ãƒã‚¤ã‚¯ã‚¹ãƒˆãƒªãƒ¼ãƒ ã®åˆæœŸåŒ–
        stream = p.open(format=FORMAT, channels=CHANNELS, rate=RATE, input=True, frames_per_buffer=CHUNK)

        # ã‚µãƒ¼ãƒãƒ¼ã‹ã‚‰ã®å¿œç­”éŸ³å£°ã‚’å†ç”Ÿã™ã‚‹ãŸã‚ã®ã‚¹ãƒˆãƒªãƒ¼ãƒ ã‚’åˆæœŸåŒ–
        output_stream = p.open(format=FORMAT, channels=CHANNELS, rate=RATE, output=True, frames_per_buffer=CHUNK)

        print("[INFO] Microphone input activated. Starting audio playback from server...")
        print()

        try:
            # éŸ³å£°é€ä¿¡ã‚¿ã‚¹ã‚¯ã¨éŸ³å£°å—ä¿¡ã‚¿ã‚¹ã‚¯ã‚’éåŒæœŸã§ä¸¦è¡Œå®Ÿè¡Œ
            send_task = asyncio.create_task(send_audio(websocket, stream, CHUNK))
            receive_task = asyncio.create_task(receive_audio(websocket, output_stream))

            # ã‚¿ã‚¹ã‚¯ãŒçµ‚äº†ã™ã‚‹ã¾ã§å¾…æ©Ÿ
            await asyncio.gather(send_task, receive_task)

        except KeyboardInterrupt:
            # ã‚­ãƒ¼ãƒœãƒ¼ãƒ‰ã®å‰²ã‚Šè¾¼ã¿ã§çµ‚äº†
            print("[Exit]")
        finally:
            # ã‚¹ãƒˆãƒªãƒ¼ãƒ ã‚’é–‰ã˜ã‚‹
            if stream.is_active():
                stream.stop_stream()
            stream.close()
            output_stream.stop_stream()
            output_stream.close()
            p.terminate()


if __name__ == "__main__":
    listener.start()
    asyncio.get_event_loop().run_until_complete(stream_audio_and_receive_response())
    listener.join()
